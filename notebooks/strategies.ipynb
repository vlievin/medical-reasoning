{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import rich\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "formatters = {\n",
    "    'accuracy': '{:,.2%}'.format,\n",
    "    'F1': '{:,.2%}'.format,\n",
    "    'precision': '{:,.2%}'.format,\n",
    "}\n",
    "\n",
    "multirun_path = Path(\"/home/valv/remote_data/17-31-14\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary = []\n",
    "records = []\n",
    "glob_keys = ['strategy']\n",
    "local_keys = ['labels', 'predictions']\n",
    "series = {}\n",
    "\n",
    "sorted_exp_paths = []\n",
    "for exp in multirun_path.iterdir():\n",
    "    if exp.is_dir():\n",
    "        exp_data = json.load(open(exp / 'data.json', 'r'))\n",
    "        sorted_exp_paths.append((exp, exp_data['accuracy']))\n",
    "sorted_exp_paths = [x[0] for x in sorted(sorted_exp_paths, key=lambda x: -x[1])]\n",
    "for exp in sorted_exp_paths:\n",
    "        exp_data = json.load(open(exp / 'data.json', 'r'))\n",
    "        exp_data['strategy'] = exp_data['strategy'].split('+')[0]\n",
    "        summary.append(exp_data)\n",
    "        series[exp_data['strategy']] = exp_data['predictions']\n",
    "        for i in range(len(exp_data['predictions'])):\n",
    "            record = {k: exp_data[k][i] for k in local_keys}\n",
    "            record.update({k:v for k,v in exp_data.items() if k in glob_keys})\n",
    "            record['qid'] = i\n",
    "            records.append(record)\n",
    "\n",
    "summary = pd.DataFrame(summary)\n",
    "records = pd.DataFrame(records)\n",
    "series = pd.DataFrame(series)\n",
    "# write the summary to file\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    summary.to_latex(buf=multirun_path / 'summary.tex',\n",
    "    columns=['strategy', 'accuracy', 'f1'],\n",
    "    float_format=\"%.2f\",\n",
    "    formatters=formatters,\n",
    "    index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Aggreement matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = len(summary)\n",
    "X = np.zeros((N, N))\n",
    "# diagonal\n",
    "for i in range(N):\n",
    "    row = summary.iloc[i]\n",
    "    acc = accuracy_score(row['labels'], row['predictions'])\n",
    "    X[i, i] = acc\n",
    "\n",
    "# top-diagonal: % of aggreement on correct answers\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j > i:\n",
    "            row_i = summary.iloc[i]\n",
    "            row_j = summary.iloc[j]\n",
    "            assert row_i['labels'] == row_j['labels']\n",
    "            labels = row_i['labels']\n",
    "            y_i = row_i['predictions']\n",
    "            y_j = row_j['predictions']\n",
    "            # filter the correct results\n",
    "            y_i = [t for t,l in zip(y_i, labels) if t ==l]\n",
    "            y_j = [t for t,l in zip(y_j, labels) if t ==l]\n",
    "            agg = sum(1 for t_i, t_j in zip(y_i, y_j) if t_i == t_j) / len(y_i)\n",
    "            # register\n",
    "            X[i, j] = agg\n",
    "# bottom-diagonal: % of aggreement on wrong answers\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j < i:\n",
    "            row_i = summary.iloc[i]\n",
    "            row_j = summary.iloc[j]\n",
    "            assert row_i['labels'] == row_j['labels']\n",
    "            labels = row_i['labels']\n",
    "            y_i = row_i['predictions']\n",
    "            y_j = row_j['predictions']\n",
    "            # filter the correct results\n",
    "            y_i = [t for t,l in zip(y_i, labels) if t != l]\n",
    "            y_j = [t for t,l in zip(y_j, labels) if t != l]\n",
    "            agg = sum(1 for t_i, t_j in zip(y_i, y_j) if t_i == t_j) / len(y_i)\n",
    "            # register\n",
    "            X[i, j] = agg\n",
    "\n",
    "\n",
    "fig, ax= plt.subplots(figsize=((16, 12)), dpi=300)\n",
    "sns.heatmap(X,\n",
    "            annot=False,\n",
    "            fmt='g',\n",
    "            ax=ax,\n",
    "            xticklabels=summary['strategy'],\n",
    "            yticklabels=summary['strategy'],\n",
    "            linewidths=.5,\n",
    "            center=0.25,\n",
    "            cmap='icefire',\n",
    "           )\n",
    "plt.tight_layout()\n",
    "plt.savefig(multirun_path / 'confusion.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "df = series\n",
    "jac_sim = 1 - pairwise_distances(df.T, metric = \"hamming\")\n",
    "# optionally convert it to a DataFrame\n",
    "jac_sim = pd.DataFrame(jac_sim, index=df.columns, columns=df.columns)\n",
    "\n",
    "g = sns.clustermap(jac_sim,\n",
    "                   # metric='matching', \n",
    "                   dendrogram_ratio=(.1, .1),\n",
    "                   cbar_pos=(0.7, 0.1, .03, .2),\n",
    "                   figsize=(20,20),\n",
    "                   # cmap=sns.cubehelix_palette(as_cmap=True, reverse=False)\n",
    "                  )\n",
    "plt.savefig(multirun_path / 'cluster.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Expert Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_first(serie):\n",
    "    x = serie.values[0]\n",
    "    assert all(x == y for y in serie.values)\n",
    "    return x\n",
    "    \n",
    "def majority_vote(serie):\n",
    "    freqs = Counter(serie.values)\n",
    "    return freqs.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "ranked_strategies = summary.sort_values('accuracy', ascending=False)['strategy'].values\n",
    "expert_data = []\n",
    "for top_n in [len(summary), 3, 5, 10]:\n",
    "    records_ = records[records['strategy'].isin(ranked_strategies[:top_n])]\n",
    "    expert = records_[['labels', 'predictions', 'qid']].groupby('qid')\n",
    "    expert = expert.agg(\n",
    "    {'labels': get_first,\n",
    "     'predictions': majority_vote,\n",
    "    })\n",
    "    acc = accuracy_score(expert['labels'], expert['predictions'])\n",
    "    prec = precision_score(expert['labels'], expert['predictions'], average='macro')\n",
    "    f1 = f1_score(expert['labels'], expert['predictions'], average='macro')\n",
    "    expert_data.append({'n_experts' : top_n, 'accuracy': acc, 'precision': prec, 'F1': f1})\n",
    "    \n",
    "expert_data = pd.DataFrame(expert_data).sort_values('n_experts', ascending=False)\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    expert_data.to_latex(buf=multirun_path / 'experts.tex',\n",
    "    columns=['n_experts', 'accuracy', 'F1', 'precision'],\n",
    "    float_format=\"%.2f\",\n",
    "    index=False)\n",
    "expert_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Aggreement matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "N = len(summary)\n",
    "X = np.zeros((N, N))\n",
    "# diagonal\n",
    "for i in range(N):\n",
    "    row = summary.iloc[i]\n",
    "    acc = accuracy_score(row['labels'], row['predictions'])\n",
    "    X[i, i] = acc\n",
    "    \n",
    "# top-diagonal: % of aggreement on correct answers\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j > i:\n",
    "            row_i = summary.iloc[i]\n",
    "            row_j = summary.iloc[j]\n",
    "            assert row_i['labels'] == row_j['labels']\n",
    "            labels = row_i['labels']\n",
    "            y_i = row_i['predictions']\n",
    "            y_j = row_j['predictions']\n",
    "            # filter the correct results\n",
    "            y_i = [t for t,l in zip(y_i, labels) if t ==l]\n",
    "            y_j = [t for t,l in zip(y_j, labels) if t ==l]\n",
    "            agg = sum(1 for t_i, t_j in zip(y_i, y_j) if t_i == t_j) / len(y_i)\n",
    "            # register\n",
    "            X[i, j] = agg\n",
    "# bottom-diagonal: % of aggreement on wrong answers\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j < i:\n",
    "            row_i = summary.iloc[i]\n",
    "            row_j = summary.iloc[j]\n",
    "            assert row_i['labels'] == row_j['labels']\n",
    "            labels = row_i['labels']\n",
    "            y_i = row_i['predictions']\n",
    "            y_j = row_j['predictions']\n",
    "            # filter the correct results\n",
    "            y_i = [t for t,l in zip(y_i, labels) if t != l]\n",
    "            y_j = [t for t,l in zip(y_j, labels) if t != l]\n",
    "            agg = sum(1 for t_i, t_j in zip(y_i, y_j) if t_i == t_j) / len(y_i)\n",
    "            # register\n",
    "            X[i, j] = agg\n",
    "    \n",
    "    \n",
    "fig, ax= plt.subplots(figsize=((16, 12)), dpi=300)\n",
    "sns.heatmap(X, \n",
    "            annot=False, \n",
    "            fmt='g', \n",
    "            ax=ax, \n",
    "            xticklabels=summary['strategy'], \n",
    "            yticklabels=summary['strategy'], \n",
    "            linewidths=.5, \n",
    "            center=0.25,\n",
    "            cmap='icefire',\n",
    "           )\n",
    "plt.tight_layout()\n",
    "plt.savefig(multirun_path / 'confusion.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "df = series\n",
    "jac_sim = 1 - pairwise_distances(df.T, metric = \"hamming\")\n",
    "# optionally convert it to a DataFrame\n",
    "jac_sim = pd.DataFrame(jac_sim, index=df.columns, columns=df.columns)\n",
    "\n",
    "g = sns.clustermap(jac_sim, \n",
    "                   # metric='matching', \n",
    "                   dendrogram_ratio=(.1, .1),\n",
    "                   cbar_pos=(0.7, 0.1, .03, .2),\n",
    "                   figsize=(20,20),\n",
    "                   # cmap=sns.cubehelix_palette(as_cmap=True, reverse=False)\n",
    "                  )\n",
    "plt.savefig(multirun_path / 'cluster.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Expert Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_first(serie):\n",
    "    x = serie.values[0]\n",
    "    assert all(x == y for y in serie.values)\n",
    "    return x\n",
    "    \n",
    "def majority_vote(serie):\n",
    "    freqs = Counter(serie.values)\n",
    "    return freqs.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "\n",
    "ranked_strategies = summary.sort_values('accuracy', ascending=False)['strategy'].values\n",
    "expert_data = []\n",
    "for top_n in [len(summary), 3, 5, 10]:\n",
    "    records_ = records[records['strategy'].isin(ranked_strategies[:top_n])]\n",
    "    expert = records_[['labels', 'predictions', 'qid']].groupby('qid')\n",
    "    expert = expert.agg(\n",
    "    {'labels': get_first,\n",
    "     'predictions': majority_vote,\n",
    "    })\n",
    "    acc = accuracy_score(expert['labels'], expert['predictions'])\n",
    "    f1 = f1_score(expert['labels'], expert['predictions'], average='macro')\n",
    "    precision = precision_score(expert['labels'], expert['predictions'], average='macro')\n",
    "    expert_data.append({'n_experts' : top_n, 'accuracy': acc, 'F1': f1, 'precision': precision})\n",
    "    \n",
    "expert_data = pd.DataFrame(expert_data).sort_values('n_experts', ascending=False)\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    expert_data.to_latex(buf=multirun_path / 'experts.tex',\n",
    "    columns=['n_experts', 'accuracy', 'precision', 'F1'],\n",
    "    formatters=formatter)\n",
    "expert_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
